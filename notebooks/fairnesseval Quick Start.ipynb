{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# fairnesseval API\n",
        "Note: you can run **[this notebook live in Google Colab](https://colab.research.google.com/github/softlab-unimore/fairnesseval/blob/main/notebooks/fairnesseval%20Quick%20Start.ipynb)**."
      ],
      "metadata": {
        "id": "-D3BoNEC_YSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-deps --force-reinstall git+https://github.com/softlab-unimore/fairnesseval@main"
      ],
      "metadata": {
        "id": "4nCp2TnDIWDN",
        "outputId": "7c79b2ba-022c-4ca3-8c68-2a8fb41b6f66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/softlab-unimore/fairnesseval@main\n",
            "  Cloning https://github.com/softlab-unimore/fairnesseval (to revision main) to /tmp/pip-req-build-igjbig7n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/softlab-unimore/fairnesseval /tmp/pip-req-build-igjbig7n\n",
            "  Resolved https://github.com/softlab-unimore/fairnesseval to commit 9fd200fa77bb1d60a7b81c4dcdb25fab824df8dd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fairnesseval\n",
            "  Building wheel for fairnesseval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairnesseval: filename=fairnesseval-0.1.0-py3-none-any.whl size=70016 sha256=ca7adf3b86872d4b707c71c02a628b3ae6abd843f7a6294eb7aa415ff90f50cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4av84jw_/wheels/f0/ae/a8/df048af1459ce9d3cd6f683b4db824dffeec6a5eae5f80b134\n",
            "Successfully built fairnesseval\n",
            "Installing collected packages: fairnesseval\n",
            "  Attempting uninstall: fairnesseval\n",
            "    Found existing installation: fairnesseval 0.1.0\n",
            "    Uninstalling fairnesseval-0.1.0:\n",
            "      Successfully uninstalled fairnesseval-0.1.0\n",
            "Successfully installed fairnesseval-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset download\n",
        "The following code will download the datasets following the instructions in aif360 errors.\n",
        "It should be changed according to your paths (python path especially)."
      ],
      "metadata": {
        "id": "L0Zlk_08JgHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Code to download datasets in colab\n",
        "import requests\n",
        "import os\n",
        "\n",
        "url_list = [\"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\",\n",
        "            'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data',\n",
        "\t'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc',\n",
        "    'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',\n",
        "\t'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test',\n",
        "\t'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names',\n",
        "            ]\n",
        "compas = \"/usr/local/lib/python3.10/dist-packages/aif360/data/raw/compas\"\n",
        "german = \"/usr/local/lib/python3.10/dist-packages/aif360/data/raw/german\"\n",
        "adult =  \"/usr/local/lib/python3.10/dist-packages/aif360/data/raw/adult\"\n",
        "save_path_list = [compas] + [german] *2 + [adult] * 3\n",
        "\n",
        "for url, save_path in zip(url_list, save_path_list):\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    full_path = os.path.join(save_path, url.split('/')[-1])\n",
        "    response = requests.get(url)\n",
        "    with open(full_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "import os\n",
        "os.makedirs('cached_data/2018/1-Year', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "d4Vs-t3QDXD2",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You need to restart the kernel"
      ],
      "metadata": {
        "id": "GoWS3XOaAV45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîÅ Restarting kernel...\")\n",
        "# get_ipython().kernel.do_shutdown(True)\n",
        "quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We0GzNtdte3I",
        "outputId": "b2958bc1-bc4b-4590-cc93-16cf4c2a9d60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fairnesseval API\n",
        "This tool provides two interfaces for running fairness experiments on your data.\n",
        "\n",
        "**1. Python Interface**\n",
        "You can define the experiment settings in the form of a Python dictionary and use one of the following Python functions to run experiments:\n",
        "    \n",
        "1.1. `fairnesseval.run.launch_experiment_by_id` let you define and organize your experiments in a python module (default at `fairnesseval.experiment_definitions`). Then you will need to call this function by specifying only the id of the experiment you want to run. **This is the reccommended interface.**\n",
        "    \n",
        "1.2. `fairnesseval.run.launch_experiment_by_config` let you run an experiment by passing the dictionary of parameters of your experiment in input.\n",
        "\n",
        "**2. Command Line Interface**\n",
        "Alternatively, you can use the command line interface of `fairnesseval.run` to specify the experiment settings using traditional CLI parameters."
      ],
      "metadata": {
        "id": "ERXd-AUb2Met"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Python Interface"
      ],
      "metadata": {
        "id": "WcWIJmEn2Qha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To launch an experiment you can run Python script that read experiment parameters from a module (default at `fairnesseval.experiment_definitions`).\n",
        "\n",
        "Loading experiment definitions is more powerful and flexible, it allows to:\n",
        "\n",
        "*   launch multiple experiments in a row.\n",
        "*   specify multiple datasets.\n",
        "*   specify multiple models.\n",
        "*   configurations are more organized and readable.\n",
        "*   have additional logging.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gn5NRU1p2hob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Define your experiment in a file.\n",
        "(You can find example of experiment configuration in `fairnesseval.experiment_definitions`).\n",
        "\n",
        "Eg.: Create `exp_def.py` and define an experiment.\n",
        "```python\n",
        "RANDOM_SEEDs_RESTRICTED_V1 = [1]\n",
        "\n",
        "TRAIN_FRACTIONS_SMALLER_DATASETS_v1 = [0.063, 0.251, 1.]\n",
        "TRAIN_FRACTIONS_v1 = [0.001, 0.004, 0.016, 0.063, 0.251, 1]  # np.geomspace(0.001,1,7) np.linspace(0.001,1,7)\n",
        "\n",
        "experiment_definitions = [\n",
        "    {\n",
        "        'experiment_id': 'new_experiment',\n",
        "        'dataset_names': ('adult_sigmod',),\n",
        "        'model_names': ('LogisticRegression',),\n",
        "        'random_seeds': RANDOM_SEEDs_RESTRICTED_V1,\n",
        "        'results_path': './demo_results'\n",
        "    }\n",
        "]\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "G_ylbpALJEml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the experiment\n",
        "Copy the path to the experiment configuration file just defined.\n",
        "\n",
        "In my case: `/content/exp_def.py`\n",
        "\n",
        "Then run the experiment in Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "ZllCbAb1M1IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "f4pdt-EGVxh9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fairnesseval as fe\n",
        "try:\n",
        "    fe.run.launch_experiment_by_id('new_experiment', '/content/exp_def.py')\n",
        "except ModuleNotFoundError as e:\n",
        "    print(e)\n",
        "    print('*'*50 + '\\n\\n\\nFollowing the previous instructions, you should \"Define your experiment in a file\" if you want torun this code.')"
      ],
      "metadata": {
        "id": "X1BhG4l2OhRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "or save the following code in a .py file to run the experiments.\n",
        "\n",
        "\n",
        "```python\n",
        "# FILE runner.py\n",
        "import fairnesseval as fe\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conf_todo = [\n",
        "        \"new_experiment\",\n",
        "        # ... (list of configurations to be executed)\n",
        "    ]\n",
        "    for x in conf_todo:\n",
        "        fe.run.launch_experiment_by_id(x, '/content/exp_def.py')\n",
        "\n",
        "```\n",
        "\n",
        "Then launch the python script"
      ],
      "metadata": {
        "id": "6TqlxFcPOhjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m runner"
      ],
      "metadata": {
        "id": "yjh9QpMb9kum",
        "outputId": "f1dde51f-fe22-40c0-ad2d-1f43ba32c674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: No module named runner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otherwise you can use `launch_experiment_by_config`.\n",
        "E.g.:"
      ],
      "metadata": {
        "id": "hRokI3ObADED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fairnesseval as fe\n",
        "fe.run.launch_experiment_by_config(\n",
        "    {\n",
        "        'experiment_id': 'new_experiment',\n",
        "        'dataset_names': ['adult_sigmod_no_SA'],\n",
        "        'model_names': ['LogisticRegression'],\n",
        "        'random_seeds': [1],\n",
        "        'results_path': './demo_results'\n",
        "    }\n",
        "    )"
      ],
      "metadata": {
        "id": "VfYrY0e9DpEe",
        "outputId": "be15c60a-cb8a-44d4-b450-6e751a01d5dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
            "pip install 'aif360[inFairness]'\n",
            "19/09/24 16:16:31 INFO:root: Parameters of experiment new_experiment\n",
            "{\"experiment_id\": \"new_experiment\",\n",
            "\t\"dataset_names\": [\"adult_sigmod_no_SA\"],\n",
            "\t\"model_names\": [\"LogisticRegression\"],\n",
            "\t\"random_seeds\": [1],\n",
            "\t\"results_path\": \"./demo_results\"}\n",
            "19/09/24 16:16:31 INFO:root: Started logging.\n",
            "19/09/24 16:16:31 INFO:root: Starting combination: base model: None, dataset_name: adult_sigmod_no_SA, model_name: LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration:\n",
            "experiment_id: new_experiment\n",
            "dataset_name: ['adult_sigmod_no_SA']\n",
            "model_name: ['LogisticRegression']\n",
            "results_path: ./demo_results\n",
            "train_fractions: [1]\n",
            "random_seeds: [1]\n",
            "metrics: default\n",
            "preprocessing: default\n",
            "split_strategy: StratifiedKFold\n",
            "train_test_fold: [0, 1, 2]\n",
            "model_params: {}\n",
            "dataset_params: {}\n",
            "debug: False\n",
            "states: None\n",
            "eps: None\n",
            "constraint_code: None\n",
            "expgrad_fractions: None\n",
            "grid_fractions: None\n",
            "exp_grid_ratio: None\n",
            "exp_subset: None\n",
            "run_linprog_step: None\n",
            "base_model_code: None\n",
            "train_test_seeds: [None]\n",
            "test_size: 0.3\n",
            "redo_tuning: False\n",
            "****************************************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]19/09/24 16:16:32 INFO:root: Starting step: random_seed: 1, train_test_seed: 1, train_test_fold: 0 \n",
            "{\"train_fractions\": 1}\n",
            "19/09/24 16:16:32 INFO:root: Starting fit...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19/09/24 16:16:32 INFO:root: Ended fit:  in: 0:00:00.197859 ||| Starting evaluation...\n",
            "19/09/24 16:16:33 INFO:root: Ended evaluation:  in: 0:00:00.432900\n",
            "19/09/24 16:16:33 INFO:root: Ended step in: 0:00:00.645734\n",
            "1it [00:00,  1.28it/s]19/09/24 16:16:33 INFO:root: Starting step: random_seed: 2, train_test_seed: 1, train_test_fold: 1 \n",
            "{\"train_fractions\": 1}\n",
            "19/09/24 16:16:33 INFO:root: Starting fit...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in: ./demo_results/new_experiment/new_experiment_adult_sigmod_no_SA.csv\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19/09/24 16:16:33 INFO:root: Ended fit:  in: 0:00:00.262313 ||| Starting evaluation...\n",
            "19/09/24 16:16:33 INFO:root: Ended evaluation:  in: 0:00:00.432723\n",
            "19/09/24 16:16:33 INFO:root: Ended step in: 0:00:00.715180\n",
            "2it [00:01,  1.33it/s]19/09/24 16:16:33 INFO:root: Starting step: random_seed: 3, train_test_seed: 1, train_test_fold: 2 \n",
            "{\"train_fractions\": 1}\n",
            "19/09/24 16:16:33 INFO:root: Starting fit...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in: ./demo_results/new_experiment/new_experiment_adult_sigmod_no_SA.csv\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19/09/24 16:16:34 INFO:root: Ended fit:  in: 0:00:00.250531 ||| Starting evaluation...\n",
            "19/09/24 16:16:34 INFO:root: Ended evaluation:  in: 0:00:00.412468\n",
            "19/09/24 16:16:34 INFO:root: Ended step in: 0:00:00.688832\n",
            "3it [00:02,  1.34it/s]\n",
            "19/09/24 16:16:34 INFO:root: Ended: None, dataset_name: adult_sigmod_no_SA, model_name: LogisticRegression in:\n",
            " 0:00:02.611224\n",
            "19/09/24 16:16:34 INFO:root: Ended experiment. It took: 0:00:02.846373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in: ./demo_results/new_experiment/new_experiment_adult_sigmod_no_SA.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLI interface\n",
        "The equivalent CLI call to run the experiment defined before is:"
      ],
      "metadata": {
        "id": "NlhpcpCTQQda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m fairnesseval.run --dataset_name adult_sigmod_no_SA --model_name LogisticRegression --experiment_id new_experiment --random_seeds 1 --results_path /content/demo_results"
      ],
      "metadata": {
        "id": "kyf4gRHoQZnC",
        "outputId": "d14916f1-a022-457a-9ef7-4a6c739526aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-19 16:22:03.160148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-19 16:22:03.184651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-19 16:22:03.192636: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-19 16:22:05.004575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
            "pip install 'aif360[inFairness]'\n",
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'fairnesseval.run' found in sys.modules after import of package 'fairnesseval', but prior to execution of 'fairnesseval.run'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Configuration:\n",
            "experiment_id: new_experiment\n",
            "dataset_name: ['adult_sigmod_no_SA']\n",
            "model_name: ['LogisticRegression']\n",
            "results_path: /content/demo_results\n",
            "train_fractions: [1]\n",
            "random_seeds: [1]\n",
            "metrics: default\n",
            "preprocessing: default\n",
            "split_strategy: StratifiedKFold\n",
            "train_test_fold: [0, 1, 2]\n",
            "model_params: {}\n",
            "dataset_params: {}\n",
            "debug: False\n",
            "states: None\n",
            "eps: None\n",
            "constraint_code: None\n",
            "expgrad_fractions: None\n",
            "grid_fractions: None\n",
            "exp_grid_ratio: None\n",
            "exp_subset: None\n",
            "run_linprog_step: None\n",
            "base_model_code: None\n",
            "train_test_seeds: [None]\n",
            "test_size: 0.3\n",
            "redo_tuning: False\n",
            "****************************************************************************************************\n",
            "0it [00:00, ?it/s]\n",
            "Saving results in: /content/demo_results/new_experiment/new_experiment_adult_sigmod_no_SA.csv\n",
            "1it [00:00,  1.39it/s]\n",
            "Saving results in: /content/demo_results/new_experiment/new_experiment_adult_sigmod_no_SA.csv\n",
            "2it [00:01,  1.45it/s]\n",
            "Saving results in: /content/demo_results/new_experiment/new_experiment_adult_sigmod_no_SA.csv\n",
            "3it [00:02,  1.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JVjlhrfCuZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpUKWAKwQ_HY"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving additional information from models\n",
        "The `fairnesseval` library allows to save additional information from the models, such as the time of each phase of the prediction process or analytics about training process.\n",
        "To do this, you need to define a `get_stats_dict` method in your model class that returns a dictionary with the desired information."
      ]
    }
  ]
}